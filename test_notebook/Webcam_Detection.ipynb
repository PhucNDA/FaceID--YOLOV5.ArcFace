{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get root path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Face_ID_Project\\FaceDetection\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\Face_ID_Project\\FaceDetection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (2.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (63.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (0.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (1.42.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (1.23.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from tensorboard) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from markdown>=2.6.8->tensorboard) (4.11.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.9.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting easydict\n",
      "  Downloading easydict-1.10.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py): started\n",
      "  Building wheel for easydict (setup.py): finished with status 'done'\n",
      "  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6492 sha256=15a952fb331b5ea10bfa8a4bb8c90aff1414a387c6253cfda6ae5c656b2561dd\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\0d\\9a\\a9\\02f3a5f0c6b2c57184661770360c58db8166f5c877780e98f2\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting mxnet\n",
      "  Downloading mxnet-1.7.0.post2-py2.py3-none-win_amd64.whl (33.1 MB)\n",
      "     ---------------------------------------- 33.1/33.1 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting numpy<1.17.0,>=1.8.2\n",
      "  Downloading numpy-1.16.6.zip (5.1 MB)\n",
      "     ---------------------------------------- 5.1/5.1 MB 7.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting requests<2.19.0,>=2.18.4\n",
      "  Downloading requests-2.18.4-py2.py3-none-any.whl (88 kB)\n",
      "     ---------------------------------------- 88.7/88.7 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting idna<2.7,>=2.5\n",
      "  Downloading idna-2.6-py2.py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.5/56.5 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 kB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2022.12.7)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Downloading urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.3/132.3 kB 7.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (setup.py): started\n",
      "  Building wheel for numpy (setup.py): still running...\n",
      "  Building wheel for numpy (setup.py): finished with status 'done'\n",
      "  Created wheel for numpy: filename=numpy-1.16.6-cp39-cp39-win_amd64.whl size=3735174 sha256=c7f5465a3e75d54926d8b4d1fdf87ee7f185fa2dd77db6fd3c15da04996b10dd\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\ce\\72\\38\\377a1055ac9b575ebba22e507856aecdc37f9bf6372703e5f9\n",
      "Successfully built numpy\n",
      "Installing collected packages: urllib3, idna, chardet, requests, numpy, graphviz, mxnet\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.11\n",
      "    Uninstalling urllib3-1.26.11:\n",
      "      Successfully uninstalled urllib3-1.26.11\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.3\n",
      "    Uninstalling numpy-1.23.3:\n",
      "      Successfully uninstalled numpy-1.23.3\n",
      "Successfully installed chardet-3.0.4 graphviz-0.8.4 idna-2.6 mxnet-1.7.0.post2 numpy-1.16.6 requests-2.18.4 urllib3-1.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.9.1 requires tensorflow-io-gcs-filesystem>=0.23.1, which is not installed.\n",
      "tensorflow 2.9.1 requires flatbuffers<2,>=1.12, but you have flatbuffers 2.0 which is incompatible.\n",
      "tensorflow 2.9.1 requires gast<=0.4.0,>=0.2.1, but you have gast 0.5.3 which is incompatible.\n",
      "tensorflow 2.9.1 requires numpy>=1.20, but you have numpy 1.16.6 which is incompatible.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.0 requires requests<3,>=2.21.0, but you have requests 2.18.4 which is incompatible.\n",
      "seaborn 0.12.0 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
      "pandas 1.4.2 requires numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.6 which is incompatible.\n",
      "opencv-python 4.7.0.68 requires numpy>=1.17.0; python_version >= \"3.7\", but you have numpy 1.16.6 which is incompatible.\n",
      "opencv-python 4.7.0.68 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.6 which is incompatible.\n",
      "opencv-python 4.7.0.68 requires numpy>=1.19.3; python_version >= \"3.9\", but you have numpy 1.16.6 which is incompatible.\n",
      "onnxruntime 1.14.0 requires numpy>=1.21.6, but you have numpy 1.16.6 which is incompatible.\n",
      "matplotlib 3.5.2 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from scikit-learn) (1.16.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (4.7.0.68)\n",
      "Collecting numpy>=1.19.3\n",
      "  Downloading numpy-1.24.2-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 14.9/14.9 MB 8.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.16.6\n",
      "    Uninstalling numpy-1.16.6:\n",
      "      Successfully uninstalled numpy-1.16.6\n",
      "Successfully installed numpy-1.24.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.9.1 requires tensorflow-io-gcs-filesystem>=0.23.1, which is not installed.\n",
      "tensorflow 2.9.1 requires flatbuffers<2,>=1.12, but you have flatbuffers 2.0 which is incompatible.\n",
      "tensorflow 2.9.1 requires gast<=0.4.0,>=0.2.1, but you have gast 0.5.3 which is incompatible.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.0 requires requests<3,>=2.21.0, but you have requests 2.18.4 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.2 which is incompatible.\n",
      "mxnet 1.7.0.post2 requires numpy<1.17.0,>=1.8.2, but you have numpy 1.24.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboard\n",
    "%pip install easydict\n",
    "%pip install mxnet\n",
    "%pip install scikit-learn\n",
    "%pip install opencv-python\n",
    "\n",
    "pip install tensorboard\n",
    "pip install easydict\n",
    "pip install mxnet\n",
    "pip install scikit-learn\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: \"'./yolov5-face'\"\n",
      "d:\\Face_ID_Project\\FaceDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5-face' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/deepcam-cn/yolov5-face\n",
    "# %cd './yolov5-face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D has no label.\n",
      " Volume Serial Number is 06F1-503F\n",
      "\n",
      " Directory of d:\\Face_ID_Project\\FaceDetection\n",
      "\n",
      "02/11/2023  11:33 AM    <DIR>          .\n",
      "02/11/2023  11:33 AM    <DIR>          ..\n",
      "02/11/2023  11:30 AM            50,371 pthTOpt.ipynb\n",
      "02/11/2023  11:35 AM            25,715 Webcam_Detection.ipynb\n",
      "02/11/2023  11:33 AM    <DIR>          yolov5-face\n",
      "02/11/2023  10:23 AM        88,302,403 yolov5m-face.onnx\n",
      "               3 File(s)     88,378,489 bytes\n",
      "               3 Dir(s)  166,514,872,320 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from torch) (4.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from torchvision) (2.18.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests->torchvision) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests->torchvision) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: onnx in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnx) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnx) (1.24.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnx) (3.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (2.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (1.24.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (1.11.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (21.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from packaging->onnxruntime) (3.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mmcv in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (9.2.0)\n",
      "Requirement already satisfied: yapf in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (0.32.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (1.24.2)\n",
      "Requirement already satisfied: regex in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (2022.10.31)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (21.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (6.0)\n",
      "Requirement already satisfied: addict in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from mmcv) (2.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from packaging->mmcv) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyYAML in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: seaborn in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: matplotlib>=3.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from seaborn) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from matplotlib>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from opencv-python) (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (1.11.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (21.3)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (1.24.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from packaging->onnxruntime) (3.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\asus\\anaconda3\\envs\\epylib\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install onnx\n",
    "%pip install onnxruntime\n",
    "%pip install mmcv\n",
    "%pip install PyYAML\n",
    "%pip install seaborn\n",
    "%pip install opencv-python\n",
    "%pip install onnxruntime\n",
    "\n",
    "\n",
    "\n",
    "# %pip install --user -r .//requirement.txt\n",
    "\n",
    "import onnxruntime as ort\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D has no label.\n",
      " Volume Serial Number is 06F1-503F\n",
      "\n",
      " Directory of d:\\Face_ID_Project\\FaceDetection\n",
      "\n",
      "02/11/2023  12:01 PM    <DIR>          .\n",
      "02/11/2023  12:01 PM    <DIR>          ..\n",
      "02/11/2023  11:30 AM            50,371 pthTOpt.ipynb\n",
      "02/11/2023  12:01 PM            44,065 Webcam_Detection.ipynb\n",
      "02/11/2023  11:42 AM    <DIR>          yolov5-face\n",
      "02/11/2023  10:23 AM        88,302,403 yolov5m-face.onnx\n",
      "               3 File(s)     88,396,839 bytes\n",
      "               3 Dir(s)  166,065,946,624 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from iresnet import iresnet50\n",
    "#from ..insightface.recognition.arcface_torch.backbones import get_model\n",
    "from pathlib import Path\n",
    "\n",
    "class ort_v5:\n",
    "    def __init__(self, img_path, onnx_model, conf_thres, iou_thres, img_size, classes, webcam=False):\n",
    "        self.webcam = webcam\n",
    "        self.img_path= img_path\n",
    "        self.onnx_model=onnx_model\n",
    "        self.conf_thres=conf_thres\n",
    "        self.iou_thres =iou_thres\n",
    "        self.img_size=img_size\n",
    "        # self.cuda= cuda\n",
    "        self.names= classes\n",
    "        self.net=None\n",
    "\n",
    "    def __call__(self):\n",
    "        #image preprocessing\n",
    "        self.net = iresnet50(False)\n",
    "        self.net.load_state_dict(torch.load('backbone.pth',map_location=torch.device('cpu')))\n",
    "        self.net.eval()\n",
    "        if self.webcam:\n",
    "          vid = cv2.VideoCapture(0)\n",
    "          while True:\n",
    "            ret, frame = vid.read()\n",
    "            output = self.detect_img(frame)\n",
    "            cv2.imshow('Face Detection', output)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "          vid.release()\n",
    "          cv2.destroyAllWindows()         \n",
    "        else:\n",
    "          image_or= cv2.imread(self.img_path)\n",
    "          self.detect_img(image_or)\n",
    "\n",
    "    def detect_img(self, image_or):\n",
    "        \n",
    "        # print(image_or)\n",
    "        image, ratio, dwdh = self.letterbox(image_or, auto=False)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = np.ascontiguousarray(image)\n",
    "        im = image.astype(np.float32)\n",
    "        im /= 255\n",
    "        # print(im.shape)\n",
    "\n",
    "        #onnxruntime session\n",
    "        session= self.ort_session()\n",
    "        outname = [i.name for i in session.get_outputs()]\n",
    "        inname = [i.name for i in session.get_inputs()]\n",
    "        # print('input-output names:',inname,outname)\n",
    "        inp = {inname[0]:im}\n",
    "\n",
    "        # ONNXRuntime inference\n",
    "        t1 = time.time()\n",
    "        outputs = session.run(outname, inp)[0]\n",
    "        t2 = time.time()\n",
    "        output= torch.from_numpy(outputs)\n",
    "        # output = torch.tensor(np.array(outputs, dtype=np.float64))\n",
    "\n",
    "        # temp = [[o[0], o[1], o[2], o[3], o[-1], 0] for o in output_temp[0]]\n",
    "        # t=output_temp[0].resize_(np.asarray(temp).shape)\n",
    "        # t = [t]\n",
    "        # output = torch.stack(t)\n",
    "        # output[0] = torch.FloatTensor(temp)        \n",
    "\n",
    "        out =self.non_max_suppression_face(output, self.conf_thres, self.iou_thres)[0]\n",
    "        \n",
    "        print(type(out))\n",
    "        print(out.shape)\n",
    "        print(out)\n",
    "        # print('yolov5 ONNXRuntime Inference Time:', t2-t1)\n",
    "        img=self.result(image_or,ratio, dwdh, out)\n",
    "        if self.webcam:\n",
    "            return img\n",
    "        else:\n",
    "            cv2.imwrite('./result.jpg', img)\n",
    "        # print('result', img.shape)\n",
    "        # cv2.imshow('result',img)\n",
    "        # cv2.waitKey(0)\n",
    " \n",
    "    # Display results\n",
    "    def result(self,img,ratio, dwdh, out):\n",
    "        names= self.class_name()\n",
    "        colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}  \n",
    "        for i,(x0,y0,x1,y1, score) in enumerate(out[:,0:5]):\n",
    "            box = np.array([x0,y0,x1,y1])\n",
    "            \n",
    "            box -= np.array(dwdh*2)\n",
    "            box /= ratio\n",
    "            box = box.round().astype(np.int32).tolist()\n",
    "            # cls_id = int(cls_id)\n",
    "            score = round(float(score),3)\n",
    "            name = names[0]\n",
    "            color = colors[name]\n",
    "            name += ' '+str(score)\n",
    "            \n",
    "            cropped_box=img[box[1]:box[3],box[0]:box[2]]\n",
    "            cropped_box = cv2.cvtColor(cropped_box, cv2.COLOR_BGR2RGB)\n",
    "            # cv2.imwrite('name.jpg',cropped_box)\n",
    "            if(type(cropped_box) == type(None)):\n",
    "                pass\n",
    "            else:\n",
    "                cropped_box= cv2.resize(cropped_box, (112, 112))\n",
    "            # print(cropp)\n",
    "            cropped_box = np.transpose(cropped_box, (2, 0, 1))\n",
    "            cropped_box = torch.from_numpy(cropped_box).unsqueeze(0).float()\n",
    "            cropped_box.div_(255).sub_(0.5).div_(0.5)\n",
    "            print(cropped_box)\n",
    "            import os\n",
    "            ts=os.listdir('database_tensor')\n",
    "            lc=0\n",
    "            w=[]\n",
    "            feat = self.net(cropped_box).detach().numpy()\n",
    "            for i in range (len(ts)):\n",
    "                tmp=np.load('database_tensor'+'/'+ts[i])\n",
    "                w.append(tmp)\n",
    "                distance = np.linalg.norm(feat-tmp)\n",
    "                if distance<=np.linalg.norm(feat - w[lc]):\n",
    "                    lc=i                     \n",
    "            cv2.rectangle(img,box[:2],box[2:],color,2)\n",
    "            cv2.putText(img,ts[lc].replace('.npy',''),(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2) \n",
    "        return img\n",
    " \n",
    "    def box_iou(self,box1, box2, eps=1e-7):\n",
    "        # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n",
    "        \"\"\"\n",
    "        Return intersection-over-union (Jaccard index) of boxes.\n",
    "        Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n",
    "        Arguments:\n",
    "            box1 (Tensor[N, 4])\n",
    "            box2 (Tensor[M, 4])\n",
    "        Returns:\n",
    "            iou (Tensor[N, M]): the NxM matrix containing the pairwise\n",
    "                IoU values for every element in boxes1 and boxes2\n",
    "        \"\"\"\n",
    "\n",
    "        # inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)\n",
    "        (a1, a2), (b1, b2) = box1.unsqueeze(1).chunk(2, 2), box2.unsqueeze(0).chunk(2, 2)\n",
    "        inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp(0).prod(2)\n",
    "\n",
    "        # IoU = inter / (area1 + area2 - inter)\n",
    "        return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)\n",
    "\n",
    "    def box_iou(box1, box2):\n",
    "        # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n",
    "        \"\"\"\n",
    "        Return intersection-over-union (Jaccard index) of boxes.\n",
    "        Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n",
    "        Arguments:\n",
    "            box1 (Tensor[N, 4])\n",
    "            box2 (Tensor[M, 4])\n",
    "        Returns:\n",
    "            iou (Tensor[N, M]): the NxM matrix containing the pairwise\n",
    "                IoU values for every element in boxes1 and boxes2\n",
    "        \"\"\"\n",
    "\n",
    "        def box_area(box):\n",
    "            # box = 4xn\n",
    "            return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "        area1 = box_area(box1.T)\n",
    "        area2 = box_area(box2.T)\n",
    "\n",
    "        # inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)\n",
    "        inter = (torch.min(box1[:, None, 2:], box2[:, 2:]) -\n",
    "                torch.max(box1[:, None, :2], box2[:, :2])).clamp(0).prod(2)\n",
    "        # iou = inter / (area1 + area2 - inter)\n",
    "        return inter / (area1[:, None] + area2 - inter)\n",
    "\n",
    "\n",
    "    def non_max_suppression_face(self, prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, labels=()):\n",
    "        \"\"\"Performs Non-Maximum Suppression (NMS) on inference results\n",
    "        Returns:\n",
    "            detections with shape: nx6 (x1, y1, x2, y2, conf, cls)\n",
    "        \"\"\"\n",
    "\n",
    "        nc = prediction.shape[2] - 15  # number of classes\n",
    "        xc = prediction[..., 4] > conf_thres  # candidates\n",
    "\n",
    "        # Settings\n",
    "        min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
    "        time_limit = 10.0  # seconds to quit after\n",
    "        redundant = True  # require redundant detections\n",
    "        multi_label = nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "        merge = False  # use merge-NMS\n",
    "\n",
    "        t = time.time()\n",
    "        output = [torch.zeros((0, 16), device=prediction.device)] * prediction.shape[0]\n",
    "        for xi, x in enumerate(prediction):  # image index, image inference\n",
    "            # Apply constraints\n",
    "            # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "            x = x[xc[xi]]  # confidence\n",
    "\n",
    "            # Cat apriori labels if autolabelling\n",
    "            if labels and len(labels[xi]):\n",
    "                l = labels[xi]\n",
    "                v = torch.zeros((len(l), nc + 15), device=x.device)\n",
    "                v[:, :4] = l[:, 1:5]  # box\n",
    "                v[:, 4] = 1.0  # conf\n",
    "                v[range(len(l)), l[:, 0].long() + 15] = 1.0  # cls\n",
    "                x = torch.cat((x, v), 0)\n",
    "\n",
    "            # If none remain process next image\n",
    "            if not x.shape[0]:\n",
    "                continue\n",
    "\n",
    "            # Compute conf\n",
    "            x[:, 15:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "            # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "            box = self.xywh2xyxy(x[:, :4])\n",
    "\n",
    "            # Detections matrix nx6 (xyxy, conf, landmarks, cls)\n",
    "            if multi_label:\n",
    "                i, j = (x[:, 15:] > conf_thres).nonzero(as_tuple=False).T\n",
    "                x = torch.cat((box[i], x[i, j + 15, None], x[i, 5:15] ,j[:, None].float()), 1)\n",
    "            else:  # best class only\n",
    "                conf, j = x[:, 15:].max(1, keepdim=True)\n",
    "                x = torch.cat((box, conf, x[:, 5:15], j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "            # Filter by class\n",
    "            if classes is not None:\n",
    "                x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "            # If none remain process next image\n",
    "            n = x.shape[0]  # number of boxes\n",
    "            if not n:\n",
    "                continue\n",
    "\n",
    "            # Batched NMS\n",
    "            c = x[:, 15:16] * (0 if agnostic else max_wh)  # classes\n",
    "            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
    "            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "            #if i.shape[0] > max_det:  # limit detections\n",
    "            #    i = i[:max_det]\n",
    "            if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
    "                # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
    "                iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
    "                weights = iou * scores[None]  # box weights\n",
    "                x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
    "                if redundant:\n",
    "                    i = i[iou.sum(1) > 1]  # require redundancy\n",
    "\n",
    "            output[xi] = x[i]\n",
    "            if (time.time() - t) > time_limit:\n",
    "                break  # time limit exceeded\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "\n",
    "    def xywh2xyxy(self, x):\n",
    "        # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "        y = torch.zeros_like(x) if isinstance(x, torch.Tensor) else np.zeros_like(x)\n",
    "        y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "        y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "        y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "        y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "        return y\n",
    "\n",
    "    # Read classes.txt \n",
    "    def class_name(self):\n",
    "        classes=[]\n",
    "        file= open(self.names,'r')\n",
    "        while True:\n",
    "          name=file.readline().strip('\\n')\n",
    "          classes.append(name)\n",
    "          if not name:\n",
    "            break\n",
    "        return classes\n",
    "\n",
    "    def letterbox(self, im, color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "        # Resize and pad image while meeting stride-multiple constraints\n",
    "        shape = im.shape[:2]  # current shape [height, width]\n",
    "        new_shape= self.img_size\n",
    "        if isinstance(new_shape, int):\n",
    "            new_shape = (new_shape, new_shape)\n",
    "\n",
    "        # Scale ratio (new / old)\n",
    "        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "        if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "            r = min(r, 1.0)\n",
    "\n",
    "        # Compute padding\n",
    "        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "        if auto:  # minimum rectangle\n",
    "            dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "        dw /= 2  # divide padding into 2 sides\n",
    "        dh /= 2\n",
    "\n",
    "        if shape[::-1] != new_unpad:  # resize\n",
    "            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "        im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "        return im, r, (dw, dh)\n",
    "\n",
    "    # Initialize ONNXRuntime session   \n",
    "    def ort_session(self):\n",
    "        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if ort.get_device()=='GPU' else ['CPUExecutionProvider']\n",
    "        session = ort.InferenceSession(self.onnx_model, providers=providers)\n",
    "        print(session.get_providers())\n",
    "        return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = './/yolov5-face//data/images/test.jpg'\n",
    "# weights = './/yolov5-face//yolov5m-face.onnx'\n",
    "weights = './yolov5m-face.onnx'\n",
    "conf = 0.7\n",
    "iou_thres = 0.5\n",
    "img_size = 640\n",
    "classes_txt = './/yolov5-face//classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPUExecutionProvider']\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 16])\n",
      "tensor([[287.8815, 296.1411, 510.3208, 566.4873,   0.8987, 345.3289, 402.4401,\n",
      "         450.4102, 406.9331, 393.2780, 467.1173, 361.8286, 520.2203, 434.7617,\n",
      "         523.6833,   0.0000]])\n",
      "tensor([[[[-0.6078, -0.6314, -0.6392,  ..., -0.7333, -0.7333, -0.7255],\n",
      "          [-0.6235, -0.6157, -0.6078,  ..., -0.7412, -0.7412, -0.7255],\n",
      "          [-0.6000, -0.6078, -0.6235,  ..., -0.7490, -0.7412, -0.7412],\n",
      "          ...,\n",
      "          [ 0.3255,  0.3098,  0.3098,  ...,  0.0118,  0.0196,  0.3412],\n",
      "          [ 0.2627,  0.2706,  0.2549,  ...,  0.0902, -0.0039, -0.0667],\n",
      "          [ 0.2549,  0.2471,  0.2471,  ...,  0.1216,  0.1059, -0.0039]],\n",
      "\n",
      "         [[-0.6078, -0.6314, -0.6392,  ..., -0.7333, -0.7333, -0.7255],\n",
      "          [-0.6235, -0.6157, -0.6078,  ..., -0.7412, -0.7412, -0.7255],\n",
      "          [-0.6000, -0.6078, -0.6235,  ..., -0.7490, -0.7412, -0.7412],\n",
      "          ...,\n",
      "          [-0.0039, -0.0039, -0.0039,  ..., -0.1686, -0.1137,  0.1922],\n",
      "          [-0.0196, -0.0196, -0.0275,  ..., -0.1608, -0.1843, -0.2157],\n",
      "          [-0.0745, -0.0510, -0.0667,  ..., -0.1843, -0.1765, -0.2157]],\n",
      "\n",
      "         [[-0.6078, -0.6314, -0.6392,  ..., -0.7333, -0.7333, -0.7255],\n",
      "          [-0.6235, -0.6157, -0.6078,  ..., -0.7412, -0.7412, -0.7255],\n",
      "          [-0.6000, -0.6078, -0.6235,  ..., -0.7490, -0.7412, -0.7412],\n",
      "          ...,\n",
      "          [ 0.0275,  0.0196, -0.0039,  ..., -0.1373, -0.0745,  0.2392],\n",
      "          [-0.0196, -0.0039, -0.0431,  ..., -0.0824, -0.1373, -0.1529],\n",
      "          [-0.0745, -0.0980, -0.1137,  ..., -0.1294, -0.0902, -0.1608]]]])\n",
      "['CPUExecutionProvider']\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 16])\n",
      "tensor([[280.0864, 291.5362, 509.6184, 566.9700,   0.8932, 342.4348, 400.9521,\n",
      "         447.0111, 405.5365, 391.1551, 470.1347, 359.9865, 523.4036, 431.6140,\n",
      "         527.4246,   0.0000]])\n",
      "tensor([[[[-0.5922, -0.6157, -0.6235,  ..., -0.7098, -0.7255, -0.7176],\n",
      "          [-0.5922, -0.6235, -0.6157,  ..., -0.7255, -0.7255, -0.7098],\n",
      "          [-0.6078, -0.6157, -0.6157,  ..., -0.7333, -0.7333, -0.7255],\n",
      "          ...,\n",
      "          [ 0.3647,  0.3412,  0.3176,  ...,  0.0353,  0.1608,  0.4824],\n",
      "          [ 0.3490,  0.3333,  0.3098,  ...,  0.0353, -0.0275,  0.1373],\n",
      "          [ 0.3255,  0.3020,  0.2941,  ...,  0.1059,  0.0510,  0.0118]],\n",
      "\n",
      "         [[-0.5922, -0.6157, -0.6235,  ..., -0.7098, -0.7255, -0.7176],\n",
      "          [-0.5922, -0.6235, -0.6157,  ..., -0.7255, -0.7255, -0.7098],\n",
      "          [-0.6078, -0.6157, -0.6157,  ..., -0.7333, -0.7333, -0.7255],\n",
      "          ...,\n",
      "          [ 0.0667,  0.0588,  0.0353,  ..., -0.1922, -0.0431,  0.2941],\n",
      "          [ 0.0588,  0.0431, -0.0039,  ..., -0.2078, -0.2627, -0.0667],\n",
      "          [-0.0039, -0.0196, -0.0275,  ..., -0.1686, -0.1922, -0.2471]],\n",
      "\n",
      "         [[-0.5922, -0.6157, -0.6235,  ..., -0.7098, -0.7255, -0.7176],\n",
      "          [-0.5922, -0.6235, -0.6157,  ..., -0.7255, -0.7255, -0.7098],\n",
      "          [-0.6078, -0.6157, -0.6157,  ..., -0.7333, -0.7333, -0.7255],\n",
      "          ...,\n",
      "          [ 0.0824,  0.0667,  0.0353,  ..., -0.1451,  0.0039,  0.3882],\n",
      "          [ 0.0745,  0.0431,  0.0039,  ..., -0.1451, -0.2000, -0.0196],\n",
      "          [ 0.0196,  0.0039, -0.0431,  ..., -0.0980, -0.1216, -0.1843]]]])\n",
      "['CPUExecutionProvider']\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 16])\n",
      "tensor([[217.8857, 276.8025, 450.3059, 561.1290,   0.8866, 283.6224, 387.4283,\n",
      "         387.0727, 388.3547, 333.5139, 449.2021, 298.8428, 504.4438, 374.7917,\n",
      "         506.4919,   0.0000]])\n",
      "tensor([[[[-0.5843, -0.6000, -0.6078,  ..., -0.6549, -0.6235, -0.5608],\n",
      "          [-0.5529, -0.6000, -0.6157,  ..., -0.6549, -0.6471, -0.6235],\n",
      "          [-0.5529, -0.6078, -0.6078,  ..., -0.6627, -0.6627, -0.6078],\n",
      "          ...,\n",
      "          [ 0.4039,  0.3804,  0.3725,  ...,  0.3725,  0.3804,  0.3725],\n",
      "          [ 0.4196,  0.3882,  0.3725,  ...,  0.3647,  0.3569,  0.3333],\n",
      "          [ 0.3882,  0.3647,  0.3804,  ...,  0.3569,  0.3569,  0.3412]],\n",
      "\n",
      "         [[-0.5765, -0.6000, -0.6078,  ..., -0.6549, -0.6235, -0.5608],\n",
      "          [-0.5529, -0.6000, -0.6157,  ..., -0.6549, -0.6471, -0.6235],\n",
      "          [-0.5529, -0.6078, -0.6078,  ..., -0.6627, -0.6627, -0.6078],\n",
      "          ...,\n",
      "          [ 0.1137,  0.0980,  0.0824,  ...,  0.1373,  0.1529,  0.1529],\n",
      "          [ 0.1059,  0.1059,  0.0980,  ...,  0.1216,  0.1451,  0.1451],\n",
      "          [ 0.1059,  0.0980,  0.1059,  ...,  0.1137,  0.1216,  0.1216]],\n",
      "\n",
      "         [[-0.5843, -0.6000, -0.6078,  ..., -0.6549, -0.6235, -0.5608],\n",
      "          [-0.5529, -0.6000, -0.6157,  ..., -0.6549, -0.6471, -0.6235],\n",
      "          [-0.5529, -0.6078, -0.6078,  ..., -0.6627, -0.6627, -0.6078],\n",
      "          ...,\n",
      "          [ 0.1529,  0.1137,  0.0824,  ...,  0.1686,  0.2078,  0.2000],\n",
      "          [ 0.1294,  0.1137,  0.0902,  ...,  0.1686,  0.2000,  0.1843],\n",
      "          [ 0.1294,  0.1059,  0.1216,  ...,  0.1686,  0.1765,  0.1843]]]])\n"
     ]
    }
   ],
   "source": [
    "ORT= ort_v5(image, weights, conf, iou_thres, (img_size, img_size), classes=classes_txt, webcam=True)\n",
    "ORT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d62d9b257c38e348b27e5f2ef5654a2827184247ee3e208187c873176bd80688"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
